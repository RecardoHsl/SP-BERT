{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrfDBptLDfYl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNYwiy1ZDgWC"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertConfig, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9I40-j8sDyeq"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model weight 存放位置\n",
        "model_path = '/content/drive/MyDrive/課程資料/深度學習/期末專題第31組/final-bert-model.pt'\n",
        "# bert tokenizer 處理過的 train data 存放位置\n",
        "train_data_path = '/content/drive/MyDrive/課程資料/深度學習/期末專題第31組/train-tensor.pt'\n",
        "# bert tokenizer 處理過的 test data 存放位置\n",
        "test_data_path = '/content/drive/MyDrive/課程資料/深度學習/期末專題第31組/test-tensor.pt'\n",
        "# 測試結果存放位置\n",
        "output_path = '/content/drive/MyDrive/課程資料/深度學習/Final/results.csv'\n",
        "\n",
        "max_length = 512\n",
        "batch_size = 1\n",
        "lr = 1e-5\n",
        "\n",
        "nums_epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8mUHIanyEqh_"
      },
      "outputs": [],
      "source": [
        "class reviews_dataest(Dataset):\n",
        "  def __init__(self, tensor_path, test=False):\n",
        "    data = torch.load(tensor_path)\n",
        "    self.p1 = data['p1']\n",
        "    self.p2 = data['p2']\n",
        "    self.test = test\n",
        "    if not test:\n",
        "      self.labels = data['labels']\n",
        "    else:\n",
        "      self.ID = data['ID']\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.p1['input_ids'].shape[0]\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    if self.test:\n",
        "      return self.p1['input_ids'][idx], self.p1['token_type_ids'][idx], self.p1['attention_mask'][idx], \\\n",
        "             self.p2['input_ids'][idx], self.p2['token_type_ids'][idx], self.p2['attention_mask'][idx], self.ID[idx]\n",
        "    return self.p1['input_ids'][idx], self.p1['token_type_ids'][idx], self.p1['attention_mask'][idx], \\\n",
        "           self.p2['input_ids'][idx], self.p2['token_type_ids'][idx], self.p2['attention_mask'][idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m1vW5hPnE7ir"
      },
      "outputs": [],
      "source": [
        "class SplitBertModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SplitBertModel, self).__init__()\n",
        "    configuration = BertConfig()\n",
        "    self.bert = BertForSequenceClassification(configuration)\n",
        "    self.bert.classifier = torch.nn.Linear(768, 5, bias=True)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.linear = torch.nn.Linear(2 * 5, 2)\n",
        "    \n",
        "\n",
        "  def forward(self, p1_id, p1_tid, p1_am, p2_id, p2_tid, p2_am):\n",
        "    p1 = self.bert(input_ids=p1_id, attention_mask=p1_am, token_type_ids=p1_tid).logits\n",
        "    p2 = self.bert(input_ids=p2_id, attention_mask=p2_am, token_type_ids=p2_tid).logits\n",
        "    \n",
        "    p = torch.cat((p1, p2), dim=1)\n",
        "    p = self.relu(p)\n",
        "    p = self.linear(p)\n",
        "\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvkv4LvSEtDT"
      },
      "outputs": [],
      "source": [
        "train_dataset = reviews_dataest(train_data_path, test=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSXnjfImEw30"
      },
      "outputs": [],
      "source": [
        "test_dataset = reviews_dataest(test_data_path, test=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6NklCPtE_3Z"
      },
      "outputs": [],
      "source": [
        "# train cell\n",
        "\n",
        "model = SplitBertModel().to(device)\n",
        "weights = torch.load(model_path, map_location=device)\n",
        "model.load_state_dict(weights)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "train_loss = np.array([])\n",
        "\n",
        "# start training\n",
        "for epoch in range(nums_epochs):\n",
        "  loop = tqdm(train_loader, leave=True)\n",
        "  t_loss = list()\n",
        "  model.train()\n",
        "  for data in loop:\n",
        "    p1_id, p1_tid, p1_am, p2_id, p2_tid, p2_am, labels = data\n",
        "    p1_id = p1_id.to(device)\n",
        "    p1_am = p1_am.to(device)\n",
        "    p1_tid = p1_tid.to(device)\n",
        "\n",
        "    p2_id = p2_id.to(device)\n",
        "    p2_am = p2_am.to(device)\n",
        "    p2_tid = p2_tid.to(device)\n",
        "    \n",
        "    labels = labels.to(device)\n",
        "\n",
        "    output = model(p1_id, p1_tid, p1_am, p2_id, p2_tid, p2_am)\n",
        "    loss = criterion(output, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loop.set_description(f'Epoch {epoch}')\n",
        "    loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    t_loss.append(loss.item())\n",
        "\n",
        "  train_loss = np.append(train_loss, np.mean(t_loss))\n",
        "  # torch.save(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx05J6F-FN8P"
      },
      "outputs": [],
      "source": [
        "# test cell\n",
        "\n",
        "with torch.no_grad():\n",
        "  model = SplitBertModel().to(device)\n",
        "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "  model.eval()\n",
        "\n",
        "  ID = np.array([], dtype=int)\n",
        "  predict = np.array([], dtype=int)\n",
        "\n",
        "  for data in tqdm(test_loader, leave=True):\n",
        "    p1_id, p1_tid, p1_am, p2_id, p2_tid, p2_am, id = data\n",
        "    p1_id = p1_id.to(device)\n",
        "    p1_am = p1_am.to(device)\n",
        "    p1_tid = p1_tid.to(device)\n",
        "\n",
        "    p2_id = p2_id.to(device)\n",
        "    p2_am = p2_am.to(device)\n",
        "    p2_tid = p2_tid.to(device)\n",
        "    \n",
        "    id = id.view(-1).to('cpu').numpy()\n",
        "    ID = np.append(ID, id)\n",
        "    \n",
        "    output = model(p1_id, p1_tid, p1_am, p2_id, p2_tid, p2_am)\n",
        "    pred = torch.argmax(output, dim=1).view(-1).to('cpu').numpy()\n",
        "    predict = np.append(predict, pred)\n",
        "\n",
        "predict_df = pd.DataFrame()\n",
        "predict_df['ID'] = ID\n",
        "predict_df['Generation'] = predict\n",
        "predict_df.to_csv(output_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
